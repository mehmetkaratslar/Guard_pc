# =======================================================================================
# ğŸ“„ Dosya AdÄ±: fall_detection.py
# ğŸ“ Konum: guard_pc_app/core/fall_detection.py
# ğŸ“Œ AÃ§Ä±klama:
# YOLOv11 tabanlÄ± insan takibi ve dÃ¼ÅŸme algÄ±lama sistemi.
# DeepSORT ile insan takibi yaparak her kiÅŸiye bir ID atar.
# Pose estimation ile dÃ¼ÅŸme olaylarÄ±nÄ± algÄ±lar.
# Kamera gÃ¶rÃ¼ntÃ¼sÃ¼ne takip ID'leri ve kareler Ã§izer.
#
# Ã–zellikler:
# - YOLOv11 pose estimation (yolo11l-pose.pt) ile insan tespiti
# - DeepSORT ile gerÃ§ek zamanlÄ± insan takibi
# - DÃ¼ÅŸme algÄ±lama: Pelvis ve baÅŸ pozisyonlarÄ±na dayalÄ±
# - GÃ¶rÃ¼ntÃ¼ gÃ¶rselleÅŸtirme: Takip ID'leri ve kareler
#
# ğŸ”— BaÄŸlantÄ±lÄ± Dosyalar:
# - ui/dashboard.py: UI entegrasyonu
# - config/settings.py: Model yolu ve ayarlar
# - utils/logger.py: Loglama
# =======================================================================================

import cv2
import numpy as np
import logging
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
from config.settings import MODEL_PATH, CONFIDENCE_THRESHOLD, FRAME_WIDTH
import ultralytics

class FallDetector:
    """
    YOLOv11 ve DeepSORT kullanarak insan takibi ve dÃ¼ÅŸme algÄ±lama sistemi.
    Singleton pattern ile tek bir Ã¶rnek oluÅŸturulur.
    """
    _instance = None

    @classmethod
    def get_instance(cls):
        """Singleton Ã¶rneÄŸini dÃ¶ndÃ¼rÃ¼r."""
        # EÄŸer Ã¶rnek yoksa, yeni bir Ã¶rnek oluÅŸtur
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def __init__(self):
        """FallDetector baÅŸlatÄ±cÄ± fonksiyonu."""
        # Singleton kontrolÃ¼
        if FallDetector._instance is not None:
            raise Exception("Bu sÄ±nÄ±f singleton! get_instance() kullanÄ±n.")
        # YOLO modelini yÃ¼kle
        try:
            self.model = YOLO(MODEL_PATH)
            logging.info(f"YOLOv11 modeli baÅŸarÄ±yla yÃ¼klendi: {MODEL_PATH}")
        except Exception as e:
            logging.error(f"YOLO model yÃ¼klenirken hata: {str(e)}")
            raise
        # DeepSORT tracker'Ä± baÅŸlat
        try:
            self.tracker = DeepSort(
                max_age=30, n_init=3, max_iou_distance=0.7,
                embedder=None, max_cosine_distance=0.3  # VarsayÄ±lan embedder
            )
            logging.info("DeepSORT tracker baÅŸarÄ±yla baÅŸlatÄ±ldÄ±.")
        except Exception as e:
            logging.error(f"DeepSORT tracker baÅŸlatÄ±lÄ±rken hata: {str(e)}", exc_info=True)
            raise
        # Ayarlar
        self.conf_threshold = CONFIDENCE_THRESHOLD
        self.frame_size = FRAME_WIDTH
        # DÃ¼ÅŸme algÄ±lama iÃ§in Ã¶nceki pozisyonlarÄ± sakla
        self.previous_positions = {}
        # Ã‡erÃ§eve sayacÄ±
        self.frame_count = 0
        self.process_interval = 0.1  # Her 0.1 saniyede bir iÅŸleme

    def get_model_info(self):
        """
        YOLOv11 modelinin bilgilerini dÃ¶ndÃ¼rÃ¼r.

        Returns:
            dict: Model sÃ¼rÃ¼mÃ¼, adÄ± ve yapÄ±landÄ±rma bilgileri.
        """
        try:
            model_info = {
                "model_name": "YOLOv11",
                "model_version": ultralytics.__version__,
                "model_path": MODEL_PATH,
                "confidence_threshold": self.conf_threshold,
                "frame_size": self.frame_size
            }
            logging.debug(f"Model bilgisi alÄ±ndÄ±: {model_info}")
            return model_info
        except Exception as e:
            logging.error(f"Model bilgisi alÄ±nÄ±rken hata: {str(e)}")
            return {}

    def get_detection_visualization(self, frame):
        """
        Ä°nsan takibi yapar ve gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶rselleÅŸtirir.

        Args:
            frame (np.ndarray): GiriÅŸ kamera gÃ¶rÃ¼ntÃ¼sÃ¼ (BGR)

        Returns:
            tuple: (GÃ¶rselleÅŸtirilmiÅŸ Ã§erÃ§eve, takip listesi)
        """
        try:
            # Ã‡erÃ§eveyi yeniden boyutlandÄ±r
            frame_resized = cv2.resize(frame, (self.frame_size, self.frame_size))
            # YOLO ile insan tespiti
            results = self.model.predict(
                frame_resized, conf=self.conf_threshold, classes=[0], verbose=False
            )
            # Tespitleri al
            detections = []
            for result in results:
                boxes = result.boxes.xyxy.cpu().numpy()  # Bounding box'lar
                confs = result.boxes.conf.cpu().numpy()  # GÃ¼ven skorlarÄ±
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2 = map(int, box)
                    conf = float(confs[i])
                    detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 0))
            # DeepSORT ile takip
            tracks = self.tracker.update_tracks(detections, frame=frame_resized)
            # Orijinal Ã§erÃ§eve boyutlarÄ±na Ã¶lÃ§eklendirme faktÃ¶rleri
            scale_x = frame.shape[1] / self.frame_size
            scale_y = frame.shape[0] / self.frame_size
            # GÃ¶rselleÅŸtirme
            annotated_frame = frame.copy()
            track_list = []
            for track in tracks:
                if not track.is_confirmed():
                    continue
                track_id = track.track_id
                bbox = track.to_ltrb()
                x1, y1, x2, y2 = map(int, [bbox[0] * scale_x, bbox[1] * scale_y,
                                         bbox[2] * scale_x, bbox[3] * scale_y])
                # Kare Ã§iz
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                # Takip ID'sini yaz
                cv2.putText(
                    annotated_frame, f"ID: {track_id}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2
                )
                track_list.append({
                    'track_id': track_id,
                    'bbox': [x1, y1, x2, y2]
                })
                logging.debug(f"Takip ID: {track_id}, Bbox: ({x1},{y1}) to ({x2},{y2})")
            return annotated_frame, track_list
        except Exception as e:
            logging.error(f"GÃ¶rselleÅŸtirme sÄ±rasÄ±nda hata: {str(e)}", exc_info=True)
            return frame, []

    def detect_fall(self, frame, tracks=None):
        """
        DÃ¼ÅŸme olayÄ±nÄ± algÄ±lar.

        Args:
            frame (np.ndarray): GiriÅŸ kamera gÃ¶rÃ¼ntÃ¼sÃ¼ (BGR)
            tracks (list, optional): Takip edilen kiÅŸilerin listesi. Varsa saÄŸlanÄ±r, yoksa hesaplanÄ±r.

        Returns:
            tuple: (DÃ¼ÅŸme durumu, gÃ¼ven skoru, takip ID'si)
        """
        try:
            # Tracks saÄŸlanmadÄ±ysa, get_detection_visualization ile al
            if tracks is None:
                _, tracks = self.get_detection_visualization(frame)
            # Ã‡erÃ§eve sayacÄ±
            self.frame_count += 1
            # DÃ¼ÅŸme algÄ±lama iÃ§in her n Ã§erÃ§evede bir kontrol
            if self.frame_count * self.process_interval < 1:
                return False, 0.0, None
            self.frame_count = 0
            # Ã‡erÃ§eveyi yeniden boyutlandÄ±r
            frame_resized = cv2.resize(frame, (self.frame_size, self.frame_size))
            # YOLO ile pose estimation
            results = self.model.predict(
                frame_resized, conf=self.conf_threshold, classes=[0], verbose=False
            )
            # DÃ¼ÅŸme algÄ±lama
            for result in results:
                if not result.keypoints:
                    continue
                keypoints = result.keypoints.xy.cpu().numpy()
                for i, kps in enumerate(keypoints):
                    if len(kps) < 17:  # Standart 17 anahtar nokta
                        continue
                    # Pelvis (12: saÄŸ kalÃ§a, 11: sol kalÃ§a) ve baÅŸ (0: burun)
                    pelvis_x = (kps[11][0] + kps[12][0]) / 2
                    pelvis_y = (kps[11][1] + kps[12][1]) / 2
                    head_x, head_y = kps[0]
                    # DÃ¼ÅŸme kriteri: Pelvis baÅŸa gÃ¶re Ã§ok aÅŸaÄŸÄ±da
                    height_ratio = (pelvis_y - head_y) / (frame_resized.shape[0])
                    if height_ratio > 0.7:  # EÅŸik
                        confidence = min(0.9, height_ratio * 1.2)
                        # En yakÄ±n track ID'sini bul
                        track_id = None
                        min_distance = float('inf')
                        cx, cy = pelvis_x * (frame.shape[1] / self.frame_size), pelvis_y * (frame.shape[0] / self.frame_size)
                        for track in tracks:
                            tx1, ty1, tx2, ty2 = track['bbox']
                            tcx = (tx1 + tx2) / 2
                            tcy = (ty1 + ty2) / 2
                            distance = np.sqrt((tcx - cx) ** 2 + (tcy - cy) ** 2)
                            if distance < min_distance:
                                min_distance = distance
                                track_id = track['track_id']
                        if track_id is not None:
                            logging.info(f"DÃ¼ÅŸme algÄ±landÄ±: ID={track_id}, GÃ¼ven={confidence:.2f}")
                            return True, confidence, track_id
            return False, 0.0, None
        except Exception as e:
            logging.error(f"DÃ¼ÅŸme algÄ±lama sÄ±rasÄ±nda hata: {str(e)}", exc_info=True)
            return False, 0.0, None

    def cleanup(self):
        """KaynaklarÄ± temizler."""
        try:
            self.tracker.delete_all_tracks()
            logging.info("DeepSORT tracker kaynaklarÄ± temizlendi.")
        except Exception as e:
            logging.error(f"Tracker temizlenirken hata: {str(e)}")