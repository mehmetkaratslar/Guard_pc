# =======================================================================================
# === PROGRAM A√áIKLAMASI ===
# Dosya Adƒ±: detection.py (YOLOv11 POSE TABANLI D√ú≈ûME ALGILAMA MOTORU)
# Konum: guard_pc_app/core/detection.py
# A√ßƒ±klama:
# Bu dosya, Guard AI uygulamasƒ±nƒ±n ana d√º≈üme algƒ±lama motorunu i√ßerir.
# Ger√ßek zamanlƒ± kamera g√∂r√ºnt√ºs√ºnden insan fig√ºrlerini tespit eder,
# YOLOv11-pose modeliyle v√ºcut pozlarƒ± √ßƒ±karƒ±r ve d√º≈üme durumunu analiz eder.
#
# Sistem hem tekli hem √ßoklu kamera desteƒüi sunar ve y√ºksek performanslƒ± g√∂rsel i≈üleme ile √ßalƒ±≈üƒ±r.

# === √ñZELLƒ∞KLER ===
# - YOLOv11-pose modeli ile ger√ßek zamanlƒ± insan tespiti
# - DeepSORT ile ki≈üi takibi
# - Pose noktalarƒ±ndan d√º≈üme durumu analizi
# - Dinamik performans ayarlamasƒ± (FPS kontrol√º)
# - √áoklu kamera desteƒüi
# - G√∂rsel √ºst√ºne bilgi yazƒ±sƒ± ekleme (overlay)
# - Sesli uyarƒ± sistemi

# === BA≈ûLICA MOD√úLLER VE KULLANIM AMACI ===
# - cv2 (OpenCV): Kamera g√∂r√ºnt√ºs√ºn√º alma ve i≈üleme
# - numpy: Matris i≈ülemleri ve matematiksel hesaplamalar
# - torch: AI modelinin √ßalƒ±≈ütƒ±rƒ±lmasƒ±
# - deep_sort_real: Ki≈üi takibi i√ßin DeepSORT algoritmasƒ±
# - threading: Arka planda √ßalƒ±≈üan algƒ±lama d√∂ng√ºs√º
# - logging: Hata ve i≈ülem kayƒ±tlarƒ± tutma
# - math / time: Geometrik hesaplamalar ve zamanlama

# === SINIFLAR ===
# - FallDetector: YOLOv11-pose ve DeepSORT temelli d√º≈üme algƒ±lama sƒ±nƒ±fƒ±

# === TEMEL FONKSƒ∞YONLAR ===
# - __init__: Gerekli modelleri ba≈ülatƒ±r, yapƒ±landƒ±rmalarƒ± y√ºkler
# - process_frame: Tek bir frame‚Äôi i≈üler, nesne tespiti yapar, takip eder
# - detect_fall: Belirli bir ki≈üinin d√º≈ü√ºp d√º≈ümediƒüini analiz eder
# - visualize_detections: Algƒ±lanan ki≈üileri g√∂r√ºnt√º √ºzerine √ßizer
# - _play_fall_alert_sound: D√º≈üme algƒ±landƒ±ƒüƒ±nda sesli uyarƒ± verir
# - cleanup: Sistem kaynaklarƒ±nƒ± serbest bƒ±rakƒ±r

# === POSE ANALƒ∞Zƒ∞ ===
# - V√ºcudun 17 farklƒ± noktasƒ±nƒ± inceler (nose, omuz, kal√ßa, dirsek vb.)
# - Anahtar noktalar √ºzerinden a√ßƒ±sal ve oran analizi yapƒ±lƒ±r
# - Ba≈ü-omuz-kal√ßa hizasƒ±, eƒüim a√ßƒ±sƒ± ve pelvis oranƒ± gibi deƒüerler deƒüerlendirilir

# === D√ú≈ûME TESPƒ∞Tƒ∞ ƒ∞√áƒ∞N KRƒ∞TERLER ===
# 1. **Ba≈ü-Pelvis Oranƒ±:** 
#    - Y√ºksek d√º≈üme riski i√ßin ba≈üƒ±n kal√ßadan √ßok daha a≈üaƒüƒ±da olmasƒ±
# 2. **Eƒüim A√ßƒ±sƒ±:**
#    - V√ºcudun yatay eksene g√∂re dik olmadƒ±ƒüƒ± durumlar
# 3. **Minimum Poz Noktasƒ± Sayƒ±sƒ±:**
#    - Yeterli sayƒ±da keypoint‚Äôin g√ºvenilir olmasƒ± gerekir
# 4. **S√ºre Kontrol√º:**
#    - Aynƒ± ki≈üi √ºzerinde belirli s√ºre boyunca tekrarlayan algƒ±lama

# === DEEPSORT ƒ∞LE Kƒ∞≈ûƒ∞ TAKƒ∞Bƒ∞ ===
# - Her ki≈üiye benzersiz ID atanƒ±r
# - Frame‚Äôler arasƒ±nda aynƒ± ki≈üiyi takip eder
# - Takip s√ºresince d√º≈üme algƒ±lamasƒ± yapƒ±lƒ±r

# === G√ñRSEL √úST√úNE Bƒ∞LGƒ∞ EKLEME ===
# - FPS g√∂sterimi
# - Kullanƒ±cƒ± kimliƒüi
# - G√ºven skoru
# - Uyarƒ± mesajƒ± (D√ú≈ûME ALGILANDI!)

# === SESLƒ∞ UYARI ===
# - D√º≈üme algƒ±landƒ±ƒüƒ±nda Windows sistem sesi √ßalar
# - Thread i√ßinde asenkron olarak √ßalƒ±≈üƒ±r

# === PERFORMANS ƒ∞ZLEME ===
# - Ortalama FPS
# - Toplam d√º≈üme sayƒ±sƒ±
# - ƒ∞≈ülem s√ºresi istatistikleri

# === HATA Y√ñNETƒ∞Mƒ∞ ===
# - T√ºm i≈ülemlerde try-except bloklarƒ±yla hatalar loglanƒ±r
# - Kullanƒ±cƒ±ya anlamlƒ± mesajlar g√∂sterilir

# === LOGGING ===
# - T√ºm i≈ülemler log dosyasƒ±na yazƒ±lƒ±r (guard_ai_v3.log)
# - Log formatƒ±: Tarih/Zaman [Seviye] Mesaj

# === TEST AMA√áLI KULLANIM ===
# - `if __name__ == "__main__":` bloƒüu ile baƒüƒ±msƒ±z √ßalƒ±≈ütƒ±rƒ±labilir
# - Basit test modunda FPS ve d√º≈üme sayƒ±sƒ± terminale yazdƒ±rƒ±lƒ±r

# === NOTLAR ===
# - Bu dosya, app.py, camera.py ve dashboard.py ile entegre √ßalƒ±≈üƒ±r
# - AI modeli deƒüi≈ükenlik g√∂sterebilir (yolo11n-pose, yolo11s-pose vs.)
# - D√º≈üme algƒ±lama hassasiyeti settings.py dosyasƒ±ndan deƒüi≈ütirilebilir
# =======================================================================================

import cv2
import numpy as np
import logging
import math
import time
import threading
import datetime
from collections import defaultdict, deque
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
from config.settings import MODEL_PATH, CONFIDENCE_THRESHOLD, FRAME_WIDTH, AVAILABLE_MODELS
import winsound

class FallDetector:
    """
    YOLOv11 Pose Estimation + DeepSORT tabanlƒ± geli≈ümi≈ü d√º≈üme algƒ±lama sistemi.
    Thread-safe Singleton pattern ile implement edildi.
    """
    _instance = None
    _lock = threading.Lock()

    @classmethod
    def get_instance(cls, model_path=None, confidence_threshold=None, frame_width=None):
        """
        Thread-safe singleton √∂rneƒüini d√∂nd√ºr√ºr.
        
        Args:
            model_path (str, optional): YOLO model dosya yolu
            confidence_threshold (float, optional): G√ºven e≈üiƒüi
            frame_width (int, optional): Frame geni≈üliƒüi
            
        Returns:
            FallDetector: Singleton instance
        """
        if cls._instance is None:
            with cls._lock:
                # Double-checked locking pattern
                if cls._instance is None:
                    cls._instance = cls(model_path, confidence_threshold, frame_width)
        return cls._instance

    @classmethod
    def reset_instance(cls):
        """Singleton instance'ƒ±nƒ± sƒ±fƒ±rlar (test ama√ßlƒ±)."""
        with cls._lock:
            if cls._instance is not None:
                try:
                    cls._instance.cleanup()
                except:
                    pass
                cls._instance = None

    def __init__(self, model_path=None, confidence_threshold=None, frame_width=None):
        """
        FallDetector ba≈ülatƒ±cƒ± fonksiyonu.
        
        Args:
            model_path (str, optional): YOLO model dosya yolu
            confidence_threshold (float, optional): G√ºven e≈üiƒüi
            frame_width (int, optional): Frame geni≈üliƒüi
        """
        if FallDetector._instance is not None:
            raise Exception("Bu sƒ±nƒ±f singleton! get_instance() kullanƒ±n.")
        
        # Parametreleri ayarla
        self.model_path = model_path or MODEL_PATH
        self.conf_threshold = confidence_threshold or CONFIDENCE_THRESHOLD
        self.frame_size = frame_width or FRAME_WIDTH
        
        # Model ve sistem bilgileri
        self.model_version = "YOLOv11-L"
        self.detector_version = "3.0"
        self.initialization_time = time.time()
        
        # Mevcut modeller listesi - config/settings.py'dan al
        self.available_models = AVAILABLE_MODELS.copy()
        
        # YOLO modelini y√ºkle (pose estimation modeli)
        try:
            self.model = YOLO(self.model_path)
            self.is_model_loaded = True
            logging.info(f"YOLOv11 Pose modeli ba≈üarƒ±yla y√ºklendi: {self.model_path}")
        except Exception as e:
            logging.error(f"YOLO model y√ºklenirken hata: {str(e)}")
            self.is_model_loaded = False
            self.model = None

        # DeepSORT tracker'ƒ± ba≈ülat
        try:
            self.tracker = DeepSort(
                max_age=30,
                n_init=3,
                max_iou_distance=0.7,
                max_cosine_distance=0.4,
                nn_budget=100
            )
            logging.info("DeepSORT tracker ba≈üarƒ±yla ba≈ülatƒ±ldƒ±.")
        except Exception as e:
            logging.error(f"DeepSORT tracker ba≈ülatƒ±lƒ±rken hata: {str(e)}")
            self.tracker = None

        # COCO pose keypoints (17 nokta)
        self.keypoint_names = [
            'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
            'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
            'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
            'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
        ]

        # D√º≈üme algƒ±lama parametreleri
        self.fall_detection_params = {
            'head_pelvis_ratio_threshold': 0.8,  # Ba≈ü-pelvis oranƒ± e≈üiƒüi
            'tilt_angle_threshold': 45,          # Eƒüiklik a√ßƒ±sƒ± e≈üiƒüi (derece)
            'continuity_frames': 5,              # S√ºreklilik i√ßin gerekli kare sayƒ±sƒ±
            'min_keypoints': 10,                 # Minimum gerekli keypoint sayƒ±sƒ±
            'confidence_threshold': 0.3          # Keypoint g√ºven e≈üiƒüi
        }

        # Tracking verileri
        self.person_tracks = {}  # {track_id: PersonTrack}
        self.fall_alerts = {}    # {track_id: fall_info}
        
        # Performans takibi
        self.frame_count = 0
        self.last_detection_time = 0
        self.detection_stats = {
            'total_detections': 0,
            'fall_detections': 0,
            'false_positives': 0,
            'processing_times': deque(maxlen=100),
            'session_start': time.time()
        }
        
        # Analytics sistemi (ui/app.py uyumluluƒüu i√ßin)
        self.analytics = AnalyticsManager()
        
        # Thread g√ºvenliƒüi i√ßin lock
        self.detection_lock = threading.Lock()

    def get_model_info(self):
        """Temel model bilgilerini d√∂nd√ºr√ºr."""
        device_type = "unknown"
        if self.model is not None:
            try:
                device_type = "cuda" if self.model.device.type == "cuda" else "cpu"
            except:
                device_type = "cpu"
        
        return {
            "model_name": "YOLOv11 Pose",
            "model_path": self.model_path,
            "model_loaded": self.is_model_loaded,
            "confidence_threshold": self.conf_threshold,
            "frame_size": self.frame_size,
            "device": device_type,
            "keypoints_count": len(self.keypoint_names),
            "tracker_available": self.tracker is not None,
            "available_models": self.available_models  # Eksik olan bu satƒ±r eklendi
        }

    def get_enhanced_model_info(self):
        """
        Geli≈ümi≈ü model bilgilerini d√∂nd√ºr√ºr (app.py uyumluluƒüu i√ßin).
        
        Returns:
            dict: Detaylƒ± model ve sistem bilgileri
        """
        basic_info = self.get_model_info()
        
        # Geli≈ümi≈ü bilgiler ekle
        enhanced_info = {
            **basic_info,
            "detector_version": self.detector_version,
            "model_version": self.model_version,
            "initialization_time": self.initialization_time,
            "uptime": time.time() - self.initialization_time,
            "detection_stats": self.detection_stats.copy(),
            "fall_detection_params": self.fall_detection_params.copy(),
            "active_tracks": len(self.person_tracks),
            "active_alerts": len(self.fall_alerts),
            "performance_metrics": self._get_performance_metrics(),
            "system_status": self._get_system_status(),
            "capabilities": {
                "pose_estimation": True,
                "object_tracking": self.tracker is not None,
                "fall_detection": True,
                "multi_person": True,
                "real_time": True,
                "keypoint_analysis": True
            },
            "supported_formats": {
                "input": ["BGR", "RGB", "GRAY"],
                "output": ["annotated_frame", "tracking_data", "pose_data"],
                "video_codecs": ["mp4", "avi", "mov"]
            }
        }
        
        return enhanced_info

    def get_enhanced_detection_visualization(self, frame):
        """
        Enhanced detection visualization method (app.py uyumluluƒüu i√ßin).
        
        Args:
            frame (np.ndarray): Giri≈ü g√∂r√ºnt√ºs√º
            
        Returns:
            tuple: (g√∂rselle≈ütirilmi≈ü_frame, track_listesi)
        """
        return self.get_detection_visualization(frame)

    def detect_enhanced_fall(self, frame, tracks=None):
        """
        Enhanced fall detection method (app.py uyumluluƒüu i√ßin).
        
        Args:
            frame (np.ndarray): Giri≈ü g√∂r√ºnt√ºs√º
            tracks (list, optional): Tracking bilgileri
            
        Returns:
            tuple: (d√º≈üme_durumu, g√ºven_skoru, track_id, analysis_result)
        """
        # Standart detect_fall metodunu √ßaƒüƒ±r ve sonuca None ekle
        is_fall, confidence, track_id = self.detect_fall(frame, tracks)
        
        # Analysis result i√ßin basit bir mock object
        analysis_result = None
        if is_fall:
            analysis_result = AnalysisResult(
                is_fall=is_fall,
                confidence=confidence,
                fall_score=confidence,
                keypoint_quality=0.8,
                pose_stability=0.7,
                risk_factors=["tilt_angle", "head_pelvis_ratio"],
                timestamp=time.time(),
                analysis_details={}
            )
        
        return is_fall, confidence, track_id, analysis_result

    def _get_performance_metrics(self):
        """Performans metriklerini hesapla."""
        processing_times = list(self.detection_stats['processing_times'])
        
        if not processing_times:
            return {
                "avg_processing_time": 0.0,
                "fps": 0.0,
                "min_processing_time": 0.0,
                "max_processing_time": 0.0
            }
        
        avg_time = np.mean(processing_times)
        fps = 1.0 / avg_time if avg_time > 0 else 0.0
        
        return {
            "avg_processing_time": float(avg_time),
            "fps": float(fps),
            "min_processing_time": float(np.min(processing_times)),
            "max_processing_time": float(np.max(processing_times)),
            "total_frames_processed": self.frame_count,
            "detection_accuracy": self._calculate_detection_accuracy()
        }

    def _calculate_detection_accuracy(self):
        """Algƒ±lama doƒüruluƒüunu hesapla."""
        total = self.detection_stats['total_detections']
        false_pos = self.detection_stats['false_positives']
        
        if total == 0:
            return 1.0
        
        accuracy = 1.0 - (false_pos / total)
        return max(0.0, min(1.0, accuracy))

    def _get_system_status(self):
        """Sistem durumunu deƒüerlendir."""
        status = "healthy"
        issues = []
        
        # Model durumu
        if not self.is_model_loaded:
            status = "warning"
            issues.append("Model y√ºkl√º deƒüil")
        
        # Tracker durumu
        if self.tracker is None:
            if status == "healthy":
                status = "warning"
            issues.append("Tracker kullanƒ±lamƒ±yor")
        
        # Performans kontrol√º
        if self.detection_stats['processing_times']:
            avg_time = np.mean(list(self.detection_stats['processing_times']))
            if avg_time > 0.5:  # 500ms'den fazla
                if status == "healthy":
                    status = "warning"
                issues.append("Yava≈ü i≈üleme")
        
        return {
            "status": status,
            "issues": issues,
            "last_check": time.time(),
            "checks_passed": len(issues) == 0
        }



    def get_detection_visualization(self, frame):
        """
        D√úZELTME: Enhanced detection visualization - keypoint'ler g√∂r√ºn√ºr
        """
        if not self.is_model_loaded or self.model is None:
            logging.warning("Model y√ºkl√º deƒüil, orijinal frame d√∂nd√ºr√ºl√ºyor")
            return frame, []
        
        start_time = time.time()
        
        with self.detection_lock:
            try:
                # Frame'i resize et
                frame_resized = cv2.resize(frame, (self.frame_size, self.frame_size))
                
                # YOLO ile pose estimation - d√º≈ü√ºk confidence
                results = self.model.predict(
                    frame_resized, 
                    conf=0.15,  # 0.50 -> 0.15 (√ßok d√º≈ü√ºk threshold)
                    classes=[0],  # sadece person class
                    verbose=False
                )
                
                # Detections'ƒ± hazƒ±rla
                detections = []
                pose_data = []
                
                for result in results:
                    if result.boxes is not None and hasattr(result.boxes, 'xyxy'):
                        try:
                            # D√úZELTME: G√ºvenli tensor handling
                            boxes = result.boxes.xyxy
                            if boxes is not None:
                                if hasattr(boxes, 'cpu'):
                                    boxes = boxes.cpu().numpy()
                                elif hasattr(boxes, 'detach'):
                                    boxes = boxes.detach().numpy()
                                elif hasattr(boxes, 'numpy'):
                                    boxes = boxes.numpy()
                                else:
                                    boxes = np.array(boxes)
                            else:
                                continue
                            
                            # Confidence deƒüerleri
                            confs = result.boxes.conf
                            if confs is not None:
                                if hasattr(confs, 'cpu'):
                                    confs = confs.cpu().numpy()
                                elif hasattr(confs, 'detach'):
                                    confs = confs.detach().numpy()
                                elif hasattr(confs, 'numpy'):
                                    confs = confs.numpy()
                                else:
                                    confs = np.array(confs)
                            else:
                                continue
                            
                            # D√úZELTME: Keypoints g√ºvenli alma
                            keypoints = None
                            keypoint_confs = None
                            if hasattr(result, 'keypoints') and result.keypoints is not None:
                                try:
                                    if hasattr(result.keypoints, 'xy') and result.keypoints.xy is not None:
                                        kp_xy = result.keypoints.xy
                                        if hasattr(kp_xy, 'cpu'):
                                            keypoints = kp_xy.cpu().numpy()
                                        elif hasattr(kp_xy, 'detach'):
                                            keypoints = kp_xy.detach().numpy()
                                        elif hasattr(kp_xy, 'numpy'):
                                            keypoints = kp_xy.numpy()
                                        else:
                                            keypoints = np.array(kp_xy)
                                    
                                    if hasattr(result.keypoints, 'conf') and result.keypoints.conf is not None:
                                        kp_conf = result.keypoints.conf
                                        if hasattr(kp_conf, 'cpu'):
                                            keypoint_confs = kp_conf.cpu().numpy()
                                        elif hasattr(kp_conf, 'detach'):
                                            keypoint_confs = kp_conf.detach().numpy()
                                        elif hasattr(kp_conf, 'numpy'):
                                            keypoint_confs = kp_conf.numpy()
                                        else:
                                            keypoint_confs = np.array(kp_conf)
                                except Exception as kp_error:
                                    logging.debug(f"Keypoint i≈üleme hatasƒ±: {kp_error}")
                                    keypoints = None
                                    keypoint_confs = None
                            
                            # Her detection i√ßin i≈üle
                            for i, (box, conf) in enumerate(zip(boxes, confs)):
                                x1, y1, x2, y2 = map(int, box)
                                
                                # Detection formatƒ±: [x, y, w, h]
                                detection = [x1, y1, x2-x1, y2-y1]
                                detections.append((detection, conf, 0))  # class_id = 0 (person)
                                
                                # Pose data ekle
                                person_keypoints = None
                                person_keypoint_confs = None
                                if keypoints is not None and i < len(keypoints):
                                    person_keypoints = keypoints[i]
                                    person_keypoint_confs = keypoint_confs[i] if keypoint_confs is not None else None
                                
                                pose_data.append({
                                    'keypoints': person_keypoints,
                                    'keypoint_confs': person_keypoint_confs,
                                    'bbox': [x1, y1, x2, y2]
                                })
                        
                        except Exception as box_error:
                            logging.debug(f"Box i≈üleme hatasƒ±: {box_error}")
                            continue

                # ƒ∞statistikleri g√ºncelle
                self.detection_stats['total_detections'] += len(detections)

                # DeepSORT ile tracking
                tracks = []
                if self.tracker is not None and len(detections) > 0:
                    try:
                        tracks = self.tracker.update_tracks(detections, frame=frame_resized)
                    except Exception as e:
                        logging.error(f"DeepSORT tracking hatasƒ±: {str(e)}")
                        tracks = []
                
                # Tracking bilgilerini g√ºncelle
                self._update_person_tracks(tracks, pose_data)
                
                # D√úZELTME: Enhanced g√∂rselle≈ütirme - keypoint'ler g√∂r√ºn√ºr
                annotated_frame = self._draw_enhanced_visualizations(frame, tracks)
                
                # Track listesi olu≈ütur
                track_list = []
                for track in tracks:
                    if hasattr(track, 'is_confirmed') and track.is_confirmed():
                        track_id = track.track_id
                        bbox = track.to_ltrb()
                        
                        # Frame boyutlarƒ±na √∂l√ßeklendir
                        scale_x = frame.shape[1] / self.frame_size
                        scale_y = frame.shape[0] / self.frame_size
                        
                        x1 = int(bbox[0] * scale_x)
                        y1 = int(bbox[1] * scale_y)
                        x2 = int(bbox[2] * scale_x)
                        y2 = int(bbox[3] * scale_y)
                        
                        track_list.append({
                            'track_id': track_id,
                            'bbox': [x1, y1, x2, y2],
                            'confidence': getattr(track, 'confidence', 0.0)
                        })
                
                # ƒ∞≈ülem s√ºresini kaydet
                processing_time = time.time() - start_time
                self.detection_stats['processing_times'].append(processing_time)
                
                return annotated_frame, track_list
                
            except Exception as e:
                logging.error(f"Detection visualization hatasƒ±: {str(e)}")
                return frame, []

    def _draw_enhanced_visualizations(self, frame, tracks):
        """
        D√úZELTME: Enhanced g√∂rselle≈ütirme - keypoint'ler √ßok g√∂r√ºn√ºr
        """
        annotated_frame = frame.copy()
        
        try:
            # Frame boyut oranlarƒ±
            scale_x = frame.shape[1] / self.frame_size
            scale_y = frame.shape[0] / self.frame_size
            
            for track in tracks:
                if not hasattr(track, 'is_confirmed') or not track.is_confirmed():
                    continue
                
                track_id = track.track_id
                bbox = track.to_ltrb()
                
                # Bbox'ƒ± orijinal frame boyutuna √∂l√ßeklendir
                x1 = int(bbox[0] * scale_x)
                y1 = int(bbox[1] * scale_y)
                x2 = int(bbox[2] * scale_x)
                y2 = int(bbox[3] * scale_y)
                
                # D√º≈üme durumu kontrol√º
                is_falling = track_id in self.fall_alerts
                box_color = (0, 0, 255) if is_falling else (0, 255, 0)  # Kƒ±rmƒ±zƒ±/Ye≈üil
                box_thickness = 4 if is_falling else 2  # Daha kalƒ±n
                
                # D√úZELTME: Enhanced bounding box
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), box_color, box_thickness)
                
                # D√úZELTME: Enhanced label - daha b√ºy√ºk
                confidence = getattr(track, 'confidence', 0.0)
                label = f"ID: {track_id}"
                if confidence > 0:
                    label += f" ({confidence:.2f})"
                
                # D√º≈üme uyarƒ±sƒ± ekle
                if is_falling:
                    label += " - FALL DETECTED!"
                
                # D√úZELTME: Daha b√ºy√ºk label arka planƒ±
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
                cv2.rectangle(annotated_frame, (x1, y1-40), (x1 + label_size[0] + 10, y1), box_color, -1)
                
                # D√úZELTME: Daha b√ºy√ºk label metni
                text_color = (255, 255, 255)
                cv2.putText(annotated_frame, label, (x1 + 5, y1-15), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, text_color, 2, cv2.LINE_AA)
                
                # D√úZELTME: Enhanced pose keypoints - √ßok g√∂r√ºn√ºr
                if track_id in self.person_tracks:
                    person_track = self.person_tracks[track_id]
                    if person_track.has_valid_pose():
                        self._draw_enhanced_pose_keypoints(annotated_frame, person_track, scale_x, scale_y, is_falling)
            
            return annotated_frame
            
        except Exception as e:
            logging.error(f"Enhanced visualization √ßizim hatasƒ±: {str(e)}")
            return frame

    def _draw_enhanced_pose_keypoints(self, frame, person_track, scale_x, scale_y, is_falling=False):
        """
        D√úZELTME: Enhanced pose keypoints - √ßok g√∂r√ºn√ºr ve renkli
        """
        try:
            keypoints = person_track.latest_keypoints
            keypoint_confs = person_track.latest_keypoint_confs
            
            if keypoints is None or keypoint_confs is None:
                return
            
            # D√úZELTME: D√º≈ü√ºk confidence threshold - daha √ßok keypoint g√∂ster
            conf_threshold = 0.1  # 0.3 -> 0.1
            
            # D√úZELTME: Enhanced keypoint colors - √ßok renkli
            keypoint_colors = [
                (255, 0, 0),    # 0: burun - mavi
                (255, 85, 0),   # 1: sol g√∂z - turuncu
                (255, 170, 0),  # 2: saƒü g√∂z - sarƒ±-turuncu
                (255, 255, 0),  # 3: sol kulak - sarƒ±
                (170, 255, 0),  # 4: saƒü kulak - ye≈üil-sarƒ±
                (85, 255, 0),   # 5: sol omuz - a√ßƒ±k ye≈üil
                (0, 255, 0),    # 6: saƒü omuz - ye≈üil
                (0, 255, 85),   # 7: sol dirsek - ye≈üil-mavi
                (0, 255, 170),  # 8: saƒü dirsek - a√ßƒ±k mavi
                (0, 255, 255),  # 9: sol bilek - cyan
                (0, 170, 255),  # 10: saƒü bilek - mavi
                (0, 85, 255),   # 11: sol kal√ßa - koyu mavi
                (0, 0, 255),    # 12: saƒü kal√ßa - mavi
                (85, 0, 255),   # 13: sol diz - mor
                (170, 0, 255),  # 14: saƒü diz - pembe-mor
                (255, 0, 255),  # 15: sol ayak - magenta
                (255, 0, 170)   # 16: saƒü ayak - pembe
            ]
            
            # D√úZELTME: Keypoint'leri √ßiz - √ßok b√ºy√ºk ve g√∂r√ºn√ºr
            for i, (keypoint, conf) in enumerate(zip(keypoints, keypoint_confs)):
                if conf > conf_threshold:
                    x = int(keypoint[0] * scale_x)
                    y = int(keypoint[1] * scale_y)
                    
                    # D√úZELTME: √áok b√ºy√ºk keypoint circles
                    radius = 8 if is_falling else 6  # 4 -> 6/8
                    color = keypoint_colors[i] if i < len(keypoint_colors) else (255, 255, 255)
                    
                    # Outer circle - daha g√∂r√ºn√ºr
                    cv2.circle(frame, (x, y), radius + 2, (0, 0, 0), -1)  # Siyah border
                    cv2.circle(frame, (x, y), radius, color, -1)
                    
                    # D√úZELTME: Keypoint numarasƒ± - debug i√ßin
                    cv2.putText(frame, str(i), (x-5, y-10), cv2.FONT_HERSHEY_SIMPLEX,
                            0.4, (255, 255, 255), 1, cv2.LINE_AA)
            
            # D√úZELTME: Enhanced skeleton √ßizgileri - daha kalƒ±n
            skeleton_connections = [
                # Ba≈ü b√∂lgesi
                [0, 1], [0, 2], [1, 3], [2, 4],  # Burun-g√∂z-kulak
                # G√∂vde
                [5, 6], [5, 11], [6, 12], [11, 12],  # Omuz-kal√ßa √ßer√ßevesi
                # Sol kol
                [5, 7], [7, 9],  # Sol omuz-dirsek-bilek
                # Saƒü kol
                [6, 8], [8, 10],  # Saƒü omuz-dirsek-bilek
                # Sol bacak
                [11, 13], [13, 15],  # Sol kal√ßa-diz-ayak
                # Saƒü bacak
                [12, 14], [14, 16],  # Saƒü kal√ßa-diz-ayak
            ]
            
            for connection in skeleton_connections:
                pt1_idx, pt2_idx = connection[0], connection[1]
                
                if (0 <= pt1_idx < len(keypoints) and 0 <= pt2_idx < len(keypoints) and
                    keypoint_confs[pt1_idx] > conf_threshold and
                    keypoint_confs[pt2_idx] > conf_threshold):
                    
                    pt1 = (int(keypoints[pt1_idx][0] * scale_x), int(keypoints[pt1_idx][1] * scale_y))
                    pt2 = (int(keypoints[pt2_idx][0] * scale_x), int(keypoints[pt2_idx][1] * scale_y))
                    
                    # D√úZELTME: √áok kalƒ±n skeleton lines
                    line_color = (0, 255, 255) if is_falling else (0, 255, 0)  # Cyan/Ye≈üil
                    line_thickness = 4 if is_falling else 3  # 2 -> 3/4
                    
                    cv2.line(frame, pt1, pt2, line_color, line_thickness, cv2.LINE_AA)
            
            # D√úZELTME: Enhanced pose info overlay
            if is_falling:
                # D√º≈üme uyarƒ±sƒ± overlay
                overlay = frame.copy()
                h, w = frame.shape[:2]
                cv2.rectangle(overlay, (0, 0), (w, 60), (0, 0, 255), -1)
                cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
                
                cv2.putText(frame, "FALL DETECTED - ENHANCED POSE ANALYSIS", 
                        (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)
                cv2.putText(frame, f"Valid Keypoints: {np.sum(keypoint_confs > conf_threshold)}/17", 
                        (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)
                        
        except Exception as e:
            logging.error(f"Enhanced pose keypoints √ßizim hatasƒ±: {str(e)}")


    def detect_fall(self, frame, tracks=None):
        """
        D√úZELTME: Ultra hassas d√º≈üme algƒ±lama - d√º≈ü√ºk threshold
        """
        if not self.is_model_loaded or self.model is None:
            return False, 0.0, None
        
        with self.detection_lock:
            try:
                self.frame_count += 1
                current_time = time.time()
                
                # Tracks yoksa detection_visualization'dan al
                if tracks is None:
                    _, tracks = self.get_detection_visualization(frame)
                
                # Her track i√ßin d√º≈üme kontrol√º
                for person_id, person_track in self.person_tracks.items():
                    fall_detected, confidence = self._analyze_fall_for_person(person_track)
                    
                    if fall_detected:
                        # D√úZELTME: S√ºreklilik kontrol√º - √ßok d√º≈ü√ºk
                        if person_id not in self.fall_alerts:
                            self.fall_alerts[person_id] = {
                                'start_time': current_time,
                                'frame_count': 1,
                                'max_confidence': confidence
                            }
                        else:
                            self.fall_alerts[person_id]['frame_count'] += 1
                            self.fall_alerts[person_id]['max_confidence'] = max(
                                self.fall_alerts[person_id]['max_confidence'], 
                                confidence
                            )
                        
                        # D√úZELTME: S√ºreklilik e≈üiƒüi - 1 frame yeterli
                        alert = self.fall_alerts[person_id]
                        if alert['frame_count'] >= 1:  # 5 -> 1 (anƒ±nda algƒ±lama)
                            logging.warning(f"üö® ULTRA HASSAS D√ú≈ûME ALGILANDI: ID={person_id}, G√ºven={alert['max_confidence']:.3f}")
                            
                            # ƒ∞statistikleri g√ºncelle
                            self.detection_stats['fall_detections'] += 1
                            
                            # Sesli uyarƒ± (thread'de)
                            threading.Thread(target=self._play_fall_alert_sound, daemon=True).start()
                            
                            return True, alert['max_confidence'], person_id
                    else:
                        # D√º≈üme algƒ±lanmadƒ±ysa alert'i temizle
                        if person_id in self.fall_alerts:
                            del self.fall_alerts[person_id]
                
                return False, 0.0, None
                
            except Exception as e:
                logging.error(f"Ultra hassas fall detection hatasƒ±: {str(e)}")
                return False, 0.0, None


    def get_detection_summary(self):
        """Algƒ±lama √∂zetini d√∂nd√ºr√ºr."""
        uptime = time.time() - self.initialization_time
        
        return {
            "session_uptime": uptime,
            "total_frames": self.frame_count,
            "total_detections": self.detection_stats['total_detections'],
            "fall_detections": self.detection_stats['fall_detections'],
            "active_tracks": len(self.person_tracks),
            "active_alerts": len(self.fall_alerts),
            "avg_fps": self._get_performance_metrics()['fps'],
            "model_status": "loaded" if self.is_model_loaded else "error",
            "tracker_status": "active" if self.tracker else "disabled"
        }

    def _update_person_tracks(self, tracks, pose_data):
        """Person tracking bilgilerini g√ºnceller."""
        try:
            # Mevcut track'leri temizle
            current_track_ids = set()
            
            for i, track in enumerate(tracks):
                if not hasattr(track, 'is_confirmed') or not track.is_confirmed():
                    continue
                    
                track_id = track.track_id
                current_track_ids.add(track_id)
                
                # Pose data'yƒ± al
                person_pose = pose_data[i] if i < len(pose_data) else None
                
                if track_id not in self.person_tracks:
                    self.person_tracks[track_id] = PersonTrack(track_id)
                
                # Track'i g√ºncelle
                self.person_tracks[track_id].update(track, person_pose)
            
            # Aktif olmayan track'leri temizle
            inactive_tracks = set(self.person_tracks.keys()) - current_track_ids
            for track_id in inactive_tracks:
                del self.person_tracks[track_id]
                if track_id in self.fall_alerts:
                    del self.fall_alerts[track_id]
                    
        except Exception as e:
            logging.error(f"Person tracks g√ºncelleme hatasƒ±: {str(e)}")




    def _analyze_fall_for_person(self, person_track):
        """
        D√úZELTME: Ultra hassas d√º≈üme analizi - test edilmi≈ü e≈üikler
        """
        if not person_track.has_valid_pose():
            return False, 0.0
            
        try:
            keypoints = person_track.latest_keypoints
            keypoint_confs = person_track.latest_keypoint_confs
            
            # D√úZELTME: √áok d√º≈ü√ºk e≈üik - daha hassas
            conf_mask = keypoint_confs > 0.1  # 0.25 -> 0.1
            valid_keypoints = np.sum(conf_mask)
            
            # D√úZELTME: Minimum keypoint sayƒ±sƒ± √ßok d√º≈ü√ºr√ºld√º
            if valid_keypoints < 4:  # 8 -> 4
                return False, 0.0
            
            # D√úZELTME: Doƒüru COCO keypoint indeksleri (0-based)
            nose = keypoints[0] if conf_mask[0] else None                    # 0: burun
            left_shoulder = keypoints[5] if conf_mask[5] else None          # 5: sol omuz
            right_shoulder = keypoints[6] if conf_mask[6] else None         # 6: saƒü omuz
            left_elbow = keypoints[7] if conf_mask[7] else None             # 7: sol dirsek
            right_elbow = keypoints[8] if conf_mask[8] else None            # 8: saƒü dirsek
            left_hip = keypoints[11] if conf_mask[11] else None             # 11: sol kal√ßa
            right_hip = keypoints[12] if conf_mask[12] else None            # 12: saƒü kal√ßa
            left_knee = keypoints[13] if conf_mask[13] else None            # 13: sol diz
            right_knee = keypoints[14] if conf_mask[14] else None           # 14: saƒü diz
            left_ankle = keypoints[15] if conf_mask[15] else None           # 15: sol ayak bileƒüi
            right_ankle = keypoints[16] if conf_mask[16] else None          # 16: saƒü ayak bileƒüi
            
            # D√úZELTME: V√ºcut merkez noktalarƒ±nƒ± hesapla
            shoulder_center = None
            if left_shoulder is not None and right_shoulder is not None:
                shoulder_center = (left_shoulder + right_shoulder) / 2
            
            hip_center = None
            if left_hip is not None and right_hip is not None:
                hip_center = (left_hip + right_hip) / 2
            
            # Ayak merkezi
            foot_center = None
            if left_ankle is not None and right_ankle is not None:
                foot_center = (left_ankle + right_ankle) / 2
            elif left_ankle is not None:
                foot_center = left_ankle
            elif right_ankle is not None:
                foot_center = right_ankle
            
            # D√úZELTME: Ana d√º≈üme algƒ±lama kriterleri - √ßok hassas
            fall_indicators = []
            fall_score = 0.0
            
            # 1. D√úZELTME: OMUZ-KAL√áA Eƒûƒ∞M A√áISI (25 derece kriteri)
            if shoulder_center is not None and hip_center is not None:
                dx = hip_center[0] - shoulder_center[0]
                dy = hip_center[1] - shoulder_center[1]
                
                if abs(dy) > 1:
                    tilt_angle = abs(math.degrees(math.atan(dx / abs(dy))))
                    
                    # D√úZELTME: 25 derece e≈üiƒüi - √ßok hassas
                    if tilt_angle > 25:  # 50 -> 25 derece
                        fall_score += 0.8  # Aƒüƒ±rlƒ±k artƒ±rƒ±ldƒ±
                        fall_indicators.append("omuz_kalca_egim")
                        logging.debug(f"D√ú≈ûME ƒ∞NDƒ∞KAT√ñR√ú: Omuz-kal√ßa eƒüimi {tilt_angle:.1f}¬∞")
                    elif tilt_angle > 15:  # D√º≈ü√ºk risk
                        fall_score += 0.4
                        fall_indicators.append("egim_riski")
            
            # 2. D√úZELTME: BAGAS-AYAK Dƒ∞KEY MESAFE ORANI - √ßok hassas
            if hip_center is not None and foot_center is not None:
                hip_foot_distance = abs(hip_center[1] - foot_center[1])
                bbox_height = person_track.latest_bbox[3] - person_track.latest_bbox[1]
                
                if bbox_height > 0:
                    height_ratio = hip_foot_distance / bbox_height
                    
                    # D√úZELTME: √áok hassas oran
                    if height_ratio < 0.4:  # 0.6 -> 0.4
                        fall_score += 0.7
                        fall_indicators.append("yukseklik_kaybi")
                        logging.debug(f"D√ú≈ûME ƒ∞NDƒ∞KAT√ñR√ú: Y√ºkseklik oranƒ± {height_ratio:.3f}")
                    elif height_ratio < 0.6:  # Orta risk
                        fall_score += 0.3
                        fall_indicators.append("yukseklik_riski")
            
            # 3. D√úZELTME: OMUZ GENƒ∞≈ûLƒ∞ƒûƒ∞ VS Y√úKSEKLIK ORANI - yatay pozisyon
            if (left_shoulder is not None and right_shoulder is not None and 
                shoulder_center is not None and foot_center is not None):
                
                shoulder_width = abs(left_shoulder[0] - right_shoulder[0])
                body_height = abs(shoulder_center[1] - foot_center[1])
                
                if body_height > 0:
                    width_height_ratio = shoulder_width / body_height
                    
                    # D√úZELTME: Daha d√º≈ü√ºk e≈üik - yatay pozisyon
                    if width_height_ratio > 0.6:  # 0.8 -> 0.6
                        fall_score += 0.8
                        fall_indicators.append("yatay_pozisyon")
                        logging.debug(f"D√ú≈ûME ƒ∞NDƒ∞KAT√ñR√ú: Geni≈ülik/y√ºkseklik oranƒ± {width_height_ratio:.3f}")
                    elif width_height_ratio > 0.5:  # Orta risk
                        fall_score += 0.4
                        fall_indicators.append("yatay_risk")
            
            # 4. D√úZELTME: BURUN KONUMU - ba≈ü a≈üaƒüƒ±da mƒ±?
            if nose is not None and hip_center is not None:
                nose_hip_diff = nose[1] - hip_center[1]  # Y farkƒ±
                
                # Burun kal√ßadan a≈üaƒüƒ±daysa (ters durum)
                if nose_hip_diff > 20:  # 20 piksel fark
                    fall_score += 0.6
                    fall_indicators.append("bas_asagida")
                    logging.debug(f"D√ú≈ûME ƒ∞NDƒ∞KAT√ñR√ú: Ba≈ü a≈üaƒüƒ±da pozisyonu")
            
            # 5. D√úZELTME: Dƒ∞Z B√úK√úLMESƒ∞ - oturma/d√º≈üme
            knee_bend_score = 0
            for knee_name, knee_point, hip_point, ankle_point in [
                ("sol_diz", left_knee, left_hip, left_ankle),
                ("sag_diz", right_knee, right_hip, right_ankle)
            ]:
                if knee_point is not None and hip_point is not None and ankle_point is not None:
                    # Kal√ßa-diz-ayak a√ßƒ±sƒ±
                    v1 = hip_point - knee_point
                    v2 = ankle_point - knee_point
                    
                    dot_product = np.dot(v1, v2)
                    norms = np.linalg.norm(v1) * np.linalg.norm(v2)
                    
                    if norms > 0:
                        cos_angle = np.clip(dot_product / norms, -1.0, 1.0)
                        knee_angle = math.degrees(math.acos(cos_angle))
                        
                        # D√úZELTME: Diz a√ßƒ±sƒ± 60 derece altƒ±ndaysa risk
                        if knee_angle < 60:  # 50 -> 60
                            knee_bend_score += 0.3
                            fall_indicators.append(f"{knee_name}_bukum")
                            logging.debug(f"D√ú≈ûME ƒ∞NDƒ∞KAT√ñR√ú: {knee_name} a√ßƒ±sƒ± {knee_angle:.1f}¬∞")
            
            fall_score += knee_bend_score
            
            # 6. D√úZELTME: EL POZƒ∞SYONU - desteklenme hareketi
            for elbow_name, elbow_point in [("sol_dirsek", left_elbow), ("sag_dirsek", right_elbow)]:
                if elbow_point is not None and foot_center is not None:
                    elbow_foot_distance = abs(elbow_point[1] - foot_center[1])
                    
                    # Dirsek ayaƒüa √ßok yakƒ±nsa (desteklenme)
                    if elbow_foot_distance < 100:  # 80 -> 100 piksel
                        fall_score += 0.4
                        fall_indicators.append(f"{elbow_name}_destek")
                        logging.debug(f"D√úZELTME ƒ∞NDƒ∞KAT√ñR√ú: {elbow_name} desteklenme")
            
            # D√úZELTME: D√ú≈ûME KARARI - √áOK D√ú≈û√úK E≈ûƒ∞K
            fall_threshold = 0.3  # 0.5 -> 0.3 (ultra hassas)
            is_fall = fall_score >= fall_threshold
            
            if is_fall:
                logging.warning(f"üö® ULTRA HASSAS D√ú≈ûME ALGILANDI! Skor: {fall_score:.3f}, ƒ∞ndikat√∂rler: {fall_indicators}")
                logging.info(f"   üìä Ge√ßerli keypoint sayƒ±sƒ±: {valid_keypoints}")
                logging.info(f"   üéØ Toplam indikat√∂r: {len(fall_indicators)}")
            elif fall_score > 0.1:  # D√º≈ü√ºk riskli durumlarƒ± da logla
                logging.debug(f"‚ö†Ô∏è D√º≈ü√ºk risk algƒ±landƒ±: Skor: {fall_score:.3f}, ƒ∞ndikat√∂rler: {fall_indicators}")
            
            return is_fall, fall_score
            
        except Exception as e:
            logging.error(f"Ultra hassas d√º≈üme analizi hatasƒ±: {str(e)}")
            return False, 0.0


    def _enhanced_detection_loop(self, camera):
        """
        D√úZELTME: Optimized detection loop - Daha akƒ±cƒ± kamera
        """
        try:
            camera_id = f"camera_{camera.camera_index}"
            logging.info(f"üé• Enhanced Detection Loop ba≈ülatƒ±ldƒ±: {camera_id}")
            
            # D√úZELTME: Performans optimizasyonu
            config = {
                'target_fps': 25,  # 30 -> 25 (daha kararlƒ±)
                'max_errors': 10,  # 15 -> 10
                'min_detection_interval': 1.5,  # 2.0 -> 1.5 saniye (daha hƒ±zlƒ±)
                'performance_log_interval': 100,  # 150 -> 100
                'ai_enabled': self.system_state['ai_model_loaded'],
                'frame_skip': 1  # Her frame'i i≈üle
            }
            
            stats = {
                'frame_count': 0,
                'detection_count': 0,
                'fall_detection_count': 0,
                'error_count': 0,
                'session_start': time.time(),
                'last_detection_time': 0,
                'total_processing_time': 0.0,
                'fps_counter': 0,
                'fps_start_time': time.time()
            }
            
            frame_duration = 1.0 / config['target_fps']
            last_fps_log = time.time()
            
            while self.system_state['running']:
                loop_start = time.time()
                
                try:
                    # D√úZELTME: Kamera durumu kontrol√º
                    if not camera or not hasattr(camera, 'is_running') or not camera.is_running:
                        time.sleep(0.1)
                        continue
                    
                    # D√úZELTME: Frame alma optimizasyonu
                    frame = camera.get_frame()
                    if frame is None or frame.size == 0:
                        stats['error_count'] += 1
                        if stats['error_count'] < config['max_errors']:
                            time.sleep(0.05)  # Kƒ±sa bekleme
                            continue
                        else:
                            logging.error(f"üí• {camera_id}: Maksimum hata sayƒ±sƒ±na ula≈üƒ±ldƒ±")
                            break
                    
                    # Frame ba≈üarƒ±lƒ± - error count sƒ±fƒ±rla
                    stats['error_count'] = 0
                    stats['frame_count'] += 1
                    stats['fps_counter'] += 1
                    processing_start = time.time()
                    
                    # D√úZELTME: AI Detection
                    if config['ai_enabled'] and self.fall_detector:
                        try:
                            # Pose detection
                            annotated_frame, tracks = self.fall_detector.get_detection_visualization(frame)
                            
                            # Stats g√ºncelle
                            if tracks:
                                stats['detection_count'] += len(tracks)
                                self.system_state['total_detections'] += len(tracks)
                                self.system_state['last_activity'] = time.time()
                            
                            # D√úZELTME: Fall Detection - Daha hassas e≈üik
                            current_time = time.time()
                            if (current_time - stats['last_detection_time']) > config['min_detection_interval']:
                                is_fall, confidence, track_id = self.fall_detector.detect_fall(frame, tracks)
                                
                                # D√úZELTME: D√º≈ü√ºk e≈üik deƒüeri
                                if is_fall and confidence > 0.4:  # 0.5 -> 0.4
                                    stats['last_detection_time'] = current_time
                                    stats['fall_detection_count'] += 1
                                    self.system_state['fall_events'] += 1
                                    
                                    logging.warning(f"üö® {camera_id} D√ú≈ûME ALGILANDI!")
                                    logging.info(f"   üìç Track ID: {track_id}")
                                    logging.info(f"   üìä Confidence: {confidence:.4f}")
                                    
                                    # D√úZELTME: Thread-safe fall handling
                                    def handle_fall():
                                        try:
                                            self._handle_enhanced_fall_detection(
                                                annotated_frame, confidence, camera_id, track_id, None
                                            )
                                        except Exception as handle_error:
                                            logging.error(f"‚ùå Fall handling hatasƒ±: {handle_error}")
                                    
                                    self.root.after(0, handle_fall)
                        
                        except Exception as ai_error:
                            logging.error(f"‚ùå {camera_id} AI detection hatasƒ±: {ai_error}")
                            annotated_frame = frame
                    
                    else:
                        annotated_frame = frame
                    
                    # D√úZELTME: Processing time
                    processing_time = time.time() - processing_start
                    stats['total_processing_time'] += processing_time
                    
                    # D√úZELTME: FPS logging - Her 5 saniyede bir
                    if time.time() - last_fps_log >= 5.0:
                        elapsed = time.time() - stats['fps_start_time']
                        if elapsed > 0:
                            current_fps = stats['fps_counter'] / elapsed
                            logging.info(f"üìä {camera_id} FPS: {current_fps:.1f}")
                            
                            # Reset
                            stats['fps_counter'] = 0
                            stats['fps_start_time'] = time.time()
                            last_fps_log = time.time()
                    
                    # D√úZELTME: Akƒ±cƒ±lƒ±k i√ßin dinamik FPS kontrol√º
                    elapsed_time = time.time() - loop_start
                    target_sleep = frame_duration - elapsed_time
                    
                    # CPU kullanƒ±mƒ±na g√∂re uyarla
                    if processing_time > frame_duration * 0.8:  # %80'den fazla CPU kullanƒ±mƒ±
                        target_sleep = max(0.01, target_sleep)  # Minimum 10ms
                    else:
                        target_sleep = max(0.005, target_sleep)  # Minimum 5ms
                    
                    if target_sleep > 0:
                        time.sleep(target_sleep)
                    
                except Exception as inner_e:
                    stats['error_count'] += 1
                    logging.error(f"‚ùå {camera_id} loop inner hatasƒ±: {str(inner_e)}")
                    
                    if stats['error_count'] >= config['max_errors']:
                        logging.error(f"üí• {camera_id} maksimum hata sayƒ±sƒ±na ula≈ütƒ±")
                        break
                    
                    time.sleep(0.1)
            
            # Final log
            total_time = time.time() - stats['session_start']
            avg_fps = stats['frame_count'] / total_time if total_time > 0 else 0
            logging.info(f"üèÅ {camera_id} Session tamamlandƒ±: {avg_fps:.1f} FPS")
            
        except Exception as e:
            logging.error(f"üí• {camera_id} Detection loop kritik hatasƒ±: {str(e)}")
        finally:
            logging.info(f"üßπ {camera_id} detection thread temizlendi")


    def _draw_visualizations(self, frame, tracks):
        """
        Tracking ve pose bilgilerini frame √ºzerine √ßizer.
        
        Args:
            frame (np.ndarray): Orijinal frame
            tracks (list): DeepSORT track listesi
            
        Returns:
            np.ndarray: G√∂rselle≈ütirilmi≈ü frame
        """
        annotated_frame = frame.copy()
        
        try:
            # Frame boyut oranlarƒ±
            scale_x = frame.shape[1] / self.frame_size
            scale_y = frame.shape[0] / self.frame_size
            
            for track in tracks:
                if not hasattr(track, 'is_confirmed') or not track.is_confirmed():
                    continue
                
                track_id = track.track_id
                bbox = track.to_ltrb()
                
                # Bbox'ƒ± orijinal frame boyutuna √∂l√ßeklendir
                x1 = int(bbox[0] * scale_x)
                y1 = int(bbox[1] * scale_y)
                x2 = int(bbox[2] * scale_x)
                y2 = int(bbox[3] * scale_y)
                
                # D√º≈üme durumu kontrol√º
                is_falling = track_id in self.fall_alerts
                box_color = (0, 0, 255) if is_falling else (0, 255, 0)  # Kƒ±rmƒ±zƒ±/Ye≈üil
                box_thickness = 3 if is_falling else 2
                
                # Bounding box √ßiz
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), box_color, box_thickness)
                
                # Track ID ve g√ºven skoru
                confidence = getattr(track, 'confidence', 0.0)
                label = f"ID: {track_id}"
                if confidence > 0:
                    label += f" ({confidence:.2f})"
                
                # D√º≈üme uyarƒ±sƒ± ekle
                if is_falling:
                    label += " - FALL DETECTED!"
                
                # Label arka planƒ±
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                cv2.rectangle(annotated_frame, (x1, y1-35), (x1 + label_size[0], y1), box_color, -1)
                
                # Label metni
                text_color = (255, 255, 255)
                cv2.putText(annotated_frame, label, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)
                
                # Pose keypoints √ßiz
                if track_id in self.person_tracks:
                    person_track = self.person_tracks[track_id]
                    if person_track.has_valid_pose():
                        self._draw_pose_keypoints(annotated_frame, person_track, scale_x, scale_y)
            
            return annotated_frame
            
        except Exception as e:
            logging.error(f"Visualization √ßizim hatasƒ±: {str(e)}")
            return frame

    def _draw_pose_keypoints(self, frame, person_track, scale_x, scale_y):
        """
        Pose keypoints'leri frame √ºzerine √ßizer.
        
        Args:
            frame (np.ndarray): Frame
            person_track (PersonTrack): Ki≈üi tracking bilgileri
            scale_x (float): X ekseni √∂l√ßekleme fakt√∂r√º
            scale_y (float): Y ekseni √∂l√ßekleme fakt√∂r√º
        """
        try:
            keypoints = person_track.latest_keypoints
            keypoint_confs = person_track.latest_keypoint_confs
            
            if keypoints is None or keypoint_confs is None:
                return
            
            # Keypoint baƒülantƒ±larƒ± (COCO format)
            skeleton = [
                [16, 14], [14, 12], [17, 15], [15, 13], [12, 13],  # Bacaklar
                [6, 12], [7, 13], [6, 7], [6, 8], [7, 9],         # G√∂vde ve kollar
                [8, 10], [9, 11], [6, 5], [5, 7], [1, 2],         # Kollar ve omuzlar
                [0, 1], [0, 2], [1, 3], [2, 4]                    # Ba≈ü
            ]
            
            # Keypoint'leri √ßiz
            for i, (keypoint, conf) in enumerate(zip(keypoints, keypoint_confs)):
                if conf > self.fall_detection_params['confidence_threshold']:
                    x = int(keypoint[0] * scale_x)
                    y = int(keypoint[1] * scale_y)
                    
                    # Keypoint rengi (√∂nemli noktalara g√∂re)
                    if i == 0:  # Burun
                        color = (255, 0, 0)  # Mavi
                    elif i in [5, 6]:  # Omuzlar
                        color = (0, 255, 255)  # Sarƒ±
                    elif i in [11, 12]:  # Kal√ßalar
                        color = (255, 0, 255)  # Magenta
                    else:
                        color = (0, 255, 0)  # Ye≈üil
                    
                    cv2.circle(frame, (x, y), 4, color, -1)
            
            # Skeleton √ßizgileri √ßiz
            for connection in skeleton:
                pt1_idx, pt2_idx = connection[0] - 1, connection[1] - 1  # COCO 1-indexed
                
                if (0 <= pt1_idx < len(keypoints) and 0 <= pt2_idx < len(keypoints) and
                    keypoint_confs[pt1_idx] > self.fall_detection_params['confidence_threshold'] and
                    keypoint_confs[pt2_idx] > self.fall_detection_params['confidence_threshold']):
                    
                    pt1 = (int(keypoints[pt1_idx][0] * scale_x), int(keypoints[pt1_idx][1] * scale_y))
                    pt2 = (int(keypoints[pt2_idx][0] * scale_x), int(keypoints[pt2_idx][1] * scale_y))
                    
                    cv2.line(frame, pt1, pt2, (0, 255, 0), 2)
                    
        except Exception as e:
            logging.error(f"Pose keypoints √ßizim hatasƒ±: {str(e)}")

    def _play_fall_alert_sound(self):
        """D√º≈üme uyarƒ±sƒ± sesini √ßalar."""
        try:
            # Windows sistem sesi
            winsound.PlaySound("SystemExclamation", winsound.SND_ALIAS | winsound.SND_ASYNC)
        except Exception as e:
            logging.warning(f"Ses √ßalma hatasƒ±: {str(e)}")

    def cleanup(self):
        """Kaynaklarƒ± temizler."""
        try:
            if self.tracker is not None:
                self.tracker.delete_all_tracks()
            self.person_tracks.clear()
            self.fall_alerts.clear()
            logging.info("FallDetector kaynaklarƒ± temizlendi.")
        except Exception as e:
            logging.error(f"Cleanup hatasƒ±: {str(e)}")


class PersonTrack:
    """
    Tek bir ki≈üinin tracking bilgilerini saklayan sƒ±nƒ±f.
    """
    
    def __init__(self, track_id):
        self.track_id = track_id
        self.latest_bbox = None
        self.latest_keypoints = None
        self.latest_keypoint_confs = None
        self.pose_history = deque(maxlen=10)  # Son 10 pose
        self.update_time = time.time()
        
    def update(self, track, pose_data):
        """Track ve pose bilgilerini g√ºnceller."""
        self.latest_bbox = track.to_ltrb()
        self.update_time = time.time()
        
        if pose_data and pose_data.get('keypoints') is not None:
            self.latest_keypoints = pose_data['keypoints']
            self.latest_keypoint_confs = pose_data.get('keypoint_confs')
            
            # Pose ge√ßmi≈üine ekle
            self.pose_history.append({
                'keypoints': self.latest_keypoints.copy(),
                'keypoint_confs': self.latest_keypoint_confs.copy() if self.latest_keypoint_confs is not None else None,
                'timestamp': self.update_time
            })
    
    def has_valid_pose(self):
        """Ge√ßerli pose bilgisi olup olmadƒ±ƒüƒ±nƒ± kontrol eder."""
        return (self.latest_keypoints is not None and 
                self.latest_keypoint_confs is not None and
                len(self.latest_keypoints) >= 17)
    
    def get_pose_stability(self):
        """Pose'un son birka√ß frame'deki kararlƒ±lƒ±ƒüƒ±nƒ± hesaplar."""
        if len(self.pose_history) < 3:
            return 0.0
            
        try:
            # Son 3 pose'u kar≈üƒ±la≈ütƒ±r
            recent_poses = list(self.pose_history)[-3:]
            stability_scores = []
            
            for i in range(len(recent_poses) - 1):
                pose1 = recent_poses[i]['keypoints']
                pose2 = recent_poses[i + 1]['keypoints']
                conf1 = recent_poses[i]['keypoint_confs']
                conf2 = recent_poses[i + 1]['keypoint_confs']
                
                if pose1 is not None and pose2 is not None:
                    # G√ºvenilir keypoint'leri kar≈üƒ±la≈ütƒ±r
                    valid_mask = (conf1 > 0.3) & (conf2 > 0.3)
                    
                    if np.sum(valid_mask) > 5:  # En az 5 ge√ßerli keypoint
                        diff = np.linalg.norm(pose1[valid_mask] - pose2[valid_mask], axis=1)
                        avg_diff = np.mean(diff)
                        stability_score = max(0, 1.0 - avg_diff / 50.0)  # 50 pixel normalizasyon
                        stability_scores.append(stability_score)
            
            return np.mean(stability_scores) if stability_scores else 0.0
            
        except Exception as e:
            logging.error(f"Pose stability hesaplama hatasƒ±: {str(e)}")
            return 0.0


class AnalyticsManager:
    """Analytics y√∂netimi i√ßin basit sƒ±nƒ±f (app.py uyumluluƒüu i√ßin)."""
    
    def __init__(self):
        self.stats = {
            'total_detections': 0,
            'fall_events': 0,
            'session_start': time.time()
        }
    
    def get_summary(self):
        """Analytics √∂zetini d√∂nd√ºr√ºr."""
        return self.stats.copy()


class AnalysisResult:
    """Analysis result container (app.py uyumluluƒüu i√ßin)."""
    
    def __init__(self, is_fall, confidence, fall_score, keypoint_quality, 
                 pose_stability, risk_factors, timestamp, analysis_details):
        self.is_fall = is_fall
        self.confidence = confidence
        self.fall_score = fall_score
        self.keypoint_quality = keypoint_quality
        self.pose_stability = pose_stability
        self.risk_factors = risk_factors
        self.timestamp = timestamp
        self.analysis_details = analysis_details