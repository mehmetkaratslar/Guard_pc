{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "9c7793b0-f96e-424e-a171-d70d2d5c47b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcvTRlHH8n5V"
      },
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "1ff5ee57-37da-49ec-bdb8-39e72307a0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Mehme\\Desktop\\Projem\\hayat_takip\\Kod\\pc\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLO11 via Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "db39f968-967d-4619-cc7a-d36da004a65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.40  Python-3.13.3 torch-2.7.0+cpu CPU (13th Gen Intel Core(TM) i9-13900H)\n",
            "Setup complete  (20 CPUs, 15.7 GB RAM, 278.9/600.0 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install \"ultralytics<=8.3.40\" supervision roboflow\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with model pre-trained on COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### CLI\n",
        "\n",
        "**NOTE:** CLI requires no customization or Python code. You can simply run all tasks from the terminal with the yolo command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbMt_M6PiXb",
        "outputId": "7308a14b-c336-445b-b65d-8c3507a678e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "Ultralytics 8.3.40 ðŸš€ Python-3.13.3 torch-2.7.0+cpu CPU (13th Gen Intel Core(TM) i9-13900H)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\n",
            "  5%|â–         | 256k/5.35M [00:00<00:02, 1.89MB/s]\n",
            " 21%|â–ˆâ–ˆ        | 1.12M/5.35M [00:00<00:00, 5.43MB/s]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2.88M/5.35M [00:00<00:00, 10.8MB/s]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4.12M/5.35M [00:00<00:00, 4.46MB/s]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5.00M/5.35M [00:01<00:00, 3.83MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 4.60MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"<frozen runpy>\"\u001b[0m, line \u001b[35m198\u001b[0m, in \u001b[35m_run_module_as_main\u001b[0m\n",
            "  File \u001b[35m\"<frozen runpy>\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35m_run_code\u001b[0m\n",
            "  File \u001b[35m\"c:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\Scripts\\yolo.exe\\__main__.py\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    sys.exit(\u001b[31mentrypoint\u001b[0m\u001b[1;31m()\u001b[0m)\n",
            "             \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\cfg\\__init__.py\"\u001b[0m, line \u001b[35m972\u001b[0m, in \u001b[35mentrypoint\u001b[0m\n",
            "    \u001b[31mgetattr(model, mode)\u001b[0m\u001b[1;31m(**overrides)\u001b[0m  # default args from model\n",
            "    \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\model.py\"\u001b[0m, line \u001b[35m557\u001b[0m, in \u001b[35mpredict\u001b[0m\n",
            "    return \u001b[31mself.predictor.predict_cli\u001b[0m\u001b[1;31m(source=source)\u001b[0m if is_cli else self.predictor(source=source, stream=stream)\n",
            "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\predictor.py\"\u001b[0m, line \u001b[35m188\u001b[0m, in \u001b[35mpredict_cli\u001b[0m\n",
            "    for _ in \u001b[1;31mgen\u001b[0m:  # sourcery skip: remove-empty-nested-block, noqa\n",
            "             \u001b[1;31m^^^\u001b[0m\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\_contextlib.py\"\u001b[0m, line \u001b[35m36\u001b[0m, in \u001b[35mgenerator_context\u001b[0m\n",
            "    response = gen.send(None)\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\predictor.py\"\u001b[0m, line \u001b[35m231\u001b[0m, in \u001b[35mstream_inference\u001b[0m\n",
            "    \u001b[31mself.setup_source\u001b[0m\u001b[1;31m(source if source is not None else self.args.source)\u001b[0m\n",
            "    \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\predictor.py\"\u001b[0m, line \u001b[35m203\u001b[0m, in \u001b[35msetup_source\u001b[0m\n",
            "    self.dataset = \u001b[31mload_inference_source\u001b[0m\u001b[1;31m(\u001b[0m\n",
            "                   \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
            "        \u001b[1;31msource=source,\u001b[0m\n",
            "        \u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
            "    ...<2 lines>...\n",
            "        \u001b[1;31mbuffer=self.args.stream_buffer,\u001b[0m\n",
            "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "    \u001b[1;31m)\u001b[0m\n",
            "    \u001b[1;31m^\u001b[0m\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\data\\build.py\"\u001b[0m, line \u001b[35m202\u001b[0m, in \u001b[35mload_inference_source\u001b[0m\n",
            "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
            "  File \u001b[35m\"C:\\Users\\Mehme\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\data\\loaders.py\"\u001b[0m, line \u001b[35m341\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
            "    raise FileNotFoundError(f\"{p} does not exist\")\n",
            "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m'C:\\Users\\Mehme\\Desktop\\Projem\\hayat_takip\\Kod\\pc\\data\\Fall_Detection.v4i.yolov11\\train\\images\\0_jpg.rf.e752f9b13bd1628078325ac03714df9d.jpg' does not exist\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=predict model=yolo11n.pt conf=0.25 source='C:\\Users\\Mehme\\Desktop\\Projem\\hayat_takip\\Kod\\pc\\data\\Fall_Detection.v4i.yolov11\\train\\images\\0_jpg.rf.e752f9b13bd1628078325ac03714df9d.jpg' save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCnCBKqzlo1F"
      },
      "source": [
        "**NOTE:** Result annotated image got saved in `{HOME}/runs/detect/predict/`. Let's display it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eIskqLWxEfPg",
        "outputId": "98a95412-c0a3-4e32-e15a-9b8916a26c4c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Mehme\\\\Desktop\\\\Projem\\\\hayat_takip\\\\Kod\\\\pc/runs/detect/predict/dog.jpeg'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m IPyImage\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mIPyImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHOME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/runs/detect/predict/dog.jpeg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py:1025\u001b[39m, in \u001b[36mImage.__init__\u001b[39m\u001b[34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28mself\u001b[39m.unconfined = unconfined\n\u001b[32m   1024\u001b[39m \u001b[38;5;28mself\u001b[39m.alt = alt\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata.get(\u001b[33m'\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m'\u001b[39m, {}):\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28mself\u001b[39m.width = metadata[\u001b[33m'\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py:343\u001b[39m, in \u001b[36mDisplayObject.__init__\u001b[39m\u001b[34m(self, data, url, filename, metadata)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.metadata = {}\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m._check_data()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py:1060\u001b[39m, in \u001b[36mImage.reload\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1058\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed:\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.retina:\n\u001b[32m   1062\u001b[39m         \u001b[38;5;28mself\u001b[39m._retina_shape()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\display.py:369\u001b[39m, in \u001b[36mDisplayObject.reload\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    368\u001b[39m     encoding = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    370\u001b[39m         \u001b[38;5;28mself\u001b[39m.data = f.read()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    372\u001b[39m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Mehme\\\\Desktop\\\\Projem\\\\hayat_takip\\\\Kod\\\\pc/runs/detect/predict/dog.jpeg'"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/detect/predict/dog.jpeg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFMBYQtMVL-B"
      },
      "source": [
        "### SDK\n",
        "\n",
        "**NOTE:** YOLO's Python interface allows for seamless integration into your Python projects, making it easy to load, run, and process the model's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx9NWF-sVN6Y",
        "outputId": "960edd1a-a289-49ce-ef90-5b98497afab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 car, 1 dog, 1 handbag, 60.1ms\n",
            "Speed: 3.9ms preprocess, 60.1ms inference, 924.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model = YOLO('yolo11n.pt')\n",
        "image = Image.open(requests.get('https://media.roboflow.com/notebooks/examples/dog.jpeg', stream=True).raw)\n",
        "result = model.predict(image, conf=0.25)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1XBAm7toMd7"
      },
      "source": [
        "**NOTE:** The obtained `result` object stores information about the location, classes, and confidence levels of the detected objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAi4PvrItTCf",
        "outputId": "61bf3391-730e-4595-c8f8-1f61f3cbc386"
      },
      "outputs": [],
      "source": [
        "result.boxes.xyxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqT2M01K1LUb",
        "outputId": "fec6c5e1-5c40-47f0-d1cd-9f1d55bb34e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.6832, 0.6284, 0.5941, 0.3923, 0.3875], device='cuda:0')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.boxes.conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKIwJ5yw1PMb",
        "outputId": "e1634e4f-d8bd-47f0-d2df-5d306d5d954f"
      },
      "outputs": [],
      "source": [
        "result.boxes.cls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PZPP_Jnn4IO"
      },
      "source": [
        "**NOTE:** YOLO11 can be easily integrated with `supervision` using the familiar `from_ultralytics` connector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4EUcnOMnw_H"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "detections = sv.Detections.from_ultralytics(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "yTjp0rx6EVl9",
        "outputId": "b65d1776-864c-4993-9da7-dc4a532a8228"
      },
      "outputs": [],
      "source": [
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image, size=(10, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSI-qYxsG6Wl"
      },
      "source": [
        "## Fine-tune YOLO11 on custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGOP0bCgH4cb"
      },
      "source": [
        "**NOTE:** When training YOLOv11, make sure your data is located in `datasets`. If you'd like to change the default location of the data you want to use for fine-tuning, you can do so through Ultralytics' `settings.json`. In this tutorial, we will use one of the [datasets](https://universe.roboflow.com/liangdianzhong/-qvdww) available on [Roboflow Universe](https://universe.roboflow.com/). When downloading, make sure to select the `yolov11` export format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "4b8633ec-fcb4-410b-877f-90e41a431257"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"rYXYR3UTgWsi80c5Gxtf\")\n",
        "project = rf.workspace(\"hong-nguyn-lixag\").project(\"fall_detection-8vxyk\")\n",
        "version = project.version(4)\n",
        "dataset = version.download(\"yolov11\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "ea236b34-8371-4088-ac87-3e988c318ec1"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train model=yolo11l.pt data={dataset.location}/data.yaml epochs=25 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Xsi-s-CfvvuB",
        "outputId": "c960fe1a-a369-4a67-f91c-622e252e4855"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e5f73294-d631-414a-94f3-3399be520470\", \"best.pt\", 51192402)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/runs/detect/train/weights/best.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mkT-rUhqQLp"
      },
      "source": [
        "**NOTE:** The results of the completed training are saved in `{HOME}/runs/detect/train/`. Let's examine them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MScstfHhArr",
        "outputId": "e7d1b537-f9cb-4f61-8ddf-3f7d3230118a"
      },
      "outputs": [],
      "source": [
        "!ls {HOME}/runs/detect/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "_J35i8Ofhjxa",
        "outputId": "d8d323f1-63bb-4676-8f59-f2eadaee0ea7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "A-urTWUkhRmn",
        "outputId": "897c36ef-6309-4257-eab6-f24c70d31fbd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/detect/train/results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "HI4nADCCj3F5",
        "outputId": "233318f8-871c-4ee9-f3e0-91a2779d056a"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "3de51aa2-03d3-41d3-eb69-e1bb06461c7a"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjc1ctZykYuf"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1nOnTQynZfeA",
        "outputId": "14a2abc8-372a-4690-c667-b82e9c8dea32"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "latest_folder = max(glob.glob(f'{HOME}/runs/detect/predict*/'), key=os.path.getmtime)\n",
        "for img in glob.glob(f'{latest_folder}/*.jpg')[:3]:\n",
        "    display(IPyImage(filename=img, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUFNm4O0znB2"
      },
      "source": [
        "## Deploy model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv11 model, youâ€™ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv11 weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y6_K1MRznB2"
      },
      "outputs": [],
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov11\", model_path=f\"{HOME}/runs/detect/train/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5K2IU_SznB2"
      },
      "outputs": [],
      "source": [
        "!pip install inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwYVU9S5znB2"
      },
      "outputs": [],
      "source": [
        "import os, random, cv2\n",
        "import supervision as sv\n",
        "import IPython\n",
        "import inference\n",
        "\n",
        "model_id = project.id.split(\"/\")[1] + \"/\" + dataset.version\n",
        "model = inference.get_model(model_id, userdata.get('ROBOFLOW_API_KEY'))\n",
        "\n",
        "# Location of test set images\n",
        "test_set_loc = dataset.location + \"/test/images/\"\n",
        "test_images = os.listdir(test_set_loc)\n",
        "\n",
        "# Run inference on 4 random test images, or fewer if fewer images are available\n",
        "for img_name in random.sample(test_images, min(4, len(test_images))):\n",
        "    print(\"Running inference on \" + img_name)\n",
        "\n",
        "    # Load image\n",
        "    image = cv2.imread(os.path.join(test_set_loc, img_name))\n",
        "\n",
        "    # Perform inference\n",
        "    results = model.infer(image, confidence=0.4, overlap=30)[0]\n",
        "    detections = sv.Detections.from_inference(results)\n",
        "\n",
        "    # Annotate boxes and labels\n",
        "    box_annotator = sv.BoxAnnotator()\n",
        "    label_annotator = sv.LabelAnnotator()\n",
        "    annotated_image = box_annotator.annotate(scene=image, detections=detections)\n",
        "    annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "    # Display annotated image\n",
        "    _, ret = cv2.imencode('.jpg', annotated_image)\n",
        "    i = IPython.display.Image(data=ret)\n",
        "    IPython.display.display(i)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
